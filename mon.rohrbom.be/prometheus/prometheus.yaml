apiVersion: v1
kind: Namespace
metadata:
  name: ops-monitoring
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-data
  namespace: ops-monitoring
spec:
  accessModes: [ReadWriteOnce]
  storageClassName: longhorn-2r
  resources:
    requests:
      storage: 50Gi
---
# ServiceAccount bleibt, wir nutzen das Token für den API-Server-Scrape.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: ops-monitoring
---
# Nur noch: /metrics vom API-Server lesen dürfen (nonResourceURL)
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-apiserver-metrics-read
rules:
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-apiserver-metrics-read-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-apiserver-metrics-read
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: ops-monitoring
---
# Statische Prometheus-Config (keine kubernetes_sd_configs mehr)
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: ops-monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
      # Prometheus selbst (UI) - Programm-/Handler-Metriken droppen
      - job_name: prometheus
        static_configs:
          - targets: ['localhost:9090']
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop

      # === NODES: Node Exporter auf jeder Node ===
      - job_name: node-exporter
        static_configs:
          - targets:
              # Hinweis: Falls Hostnames im Pod nicht resolvbar sind, lieber IPs eintragen.
              - 'cp-1:9100'
              - 'cp-2:9100'
              - 'cp-3:9100'
              - 'wk-1:9100'
              - 'wk-2:9100'
              - 'wk-3:9100'
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop

      # === INGRESS: NGINX Controller Metrics ===
      - job_name: nginx-ingress
        static_configs:
          - targets:
              - 'ingress-vlan10-mgmt-ingress-nginx-controller-metrics.ingress-vlan10-mgmt.svc:10254'
              - 'ingress-vlan20-internal-ingress-nginx-controller-metrics.ingress-vlan20-internal.svc:10254'
              - 'ingress-vlan30-public-ingress-nginx-controller-metrics.ingress-vlan30-public.svc:10254'
              - 'ingress-vlan100-admin-ingress-nginx-controller-metrics.ingress-vlan100-admin.svc:10254'
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop

      # === CLUSTER HEALTH: API-Server (/metrics) ===
      - job_name: kubernetes-apiserver
        scheme: https
        static_configs:
          - targets: ['kubernetes.default.svc:443']
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop

      # === CLUSTER HEALTH: CoreDNS ===
      - job_name: coredns
        static_configs:
          - targets: ['kube-dns.kube-system.svc:9153']
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop

      # === CLUSTER HEALTH: kube-state-metrics (Zustand/Verfügbarkeit) ===
      - job_name: kube-state-metrics
        static_configs:
          - targets: ['kube-state-metrics.ops-monitoring.svc:8080']
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop

      # === STORAGE: Longhorn ===
      - job_name: longhorn
        dns_sd_configs:
          - names: ['_metrics._tcp.longhorn-manager-metrics.longhorn-system.svc']
            type: SRV
            refresh_interval: 1m
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: '^(go_.*|process_.*|promhttp_.*)$'
            action: drop
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: ops-monitoring
  labels: { app: prometheus }
spec:
  replicas: 1
  strategy: { type: Recreate }
  selector: { matchLabels: { app: prometheus } }
  template:
    metadata:
      labels: { app: prometheus }
    spec:
      serviceAccountName: prometheus
      securityContext:
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
      containers:
        - name: prometheus
          image: prom/prometheus:latest
          imagePullPolicy: IfNotPresent
          args:
            - --config.file=/etc/prometheus/prometheus.yml
            - --storage.tsdb.path=/prometheus
            - --storage.tsdb.retention.time=10y
            # - --web.enable-lifecycle  # optional: POST /-/reload
          ports:
            - name: http
              containerPort: 9090
          env:
            - { name: TZ, value: Europe/Berlin }
          volumeMounts:
            - { name: data,   mountPath: /prometheus }
            - { name: config, mountPath: /etc/prometheus/prometheus.yml, subPath: prometheus.yml }
          readinessProbe:
            httpGet: { path: /-/ready, port: http }
            initialDelaySeconds: 10
            periodSeconds: 10
          livenessProbe:
            httpGet: { path: /-/healthy, port: http }
            initialDelaySeconds: 30
            periodSeconds: 20
          resources:
            requests: { cpu: 200m, memory: 1Gi }
            limits:   { cpu: "2",  memory: 4Gi }
      volumes:
        - name: data
          persistentVolumeClaim: { claimName: prometheus-data }
        - name: config
          configMap: { name: prometheus-config }
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: ops-monitoring
spec:
  type: ClusterIP
  selector: { app: prometheus }
  ports:
    - name: http
      port: 9090
      targetPort: http
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: prometheus
  namespace: ops-monitoring
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-dns
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
spec:
  ingressClassName: nginx-mgmt
  rules:
    - host: prometheus.mon.rohrbom.be
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service: { name: prometheus, port: { number: 9090 } }
  tls:
    - hosts: [prometheus.mon.rohrbom.be]
      secretName: prometheus-tls
---
# Zugriff nur aus ops-monitoring sowie vom mgmt-Ingress-Namespace
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: prometheus-allow-ops-and-ingress
  namespace: ops-monitoring
spec:
  podSelector: { matchLabels: { app: prometheus } }
  policyTypes: [Ingress]
  ingress:
    - from:
        - namespaceSelector:
            matchLabels: { kubernetes.io/metadata.name: ops-monitoring }
        - namespaceSelector:
            matchLabels: { kubernetes.io/metadata.name: ingress-vlan10-mgmt }
      ports:
        - protocol: TCP
          port: 9090
